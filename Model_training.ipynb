{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOaWGSivqMfD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. КОНСТАНТЫ, ИМПОРТЫ И ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ\n",
        "\n",
        "# Параметры данных\n",
        "N_POINTS = 2048   # Длина входного сигнала КПМГ\n",
        "T_MAX = 12.282    # Максимальное время сигнала КПМГ в секундах(ограничение, при больших Т2)\n",
        "NOISE_STD = 0.006 # Уровень шума\n",
        "\n",
        "# диапазно значений Т2\n",
        "T2_MIN = 0.1\n",
        "T2_MAX = 5.0\n",
        "\n",
        "# Массив времени\n",
        "T_ECHOES = torch.linspace(0, T_MAX, N_POINTS)\n",
        "CHECKPOINT_PATH = \"best_nmr_param_cnn.pth\" #загрузка модели, которая была обучена\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Инициализация Весов\n",
        "def init_weights(m):\n",
        "    \"\"\"Инициализирует веса для слоев Linear и Conv1d (Kaiming Uniform).\"\"\"\n",
        "    if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
        "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "# 2. КЛАСС ДАТАСЕТА (Версия для создания датасеты параллельно на ОЗУ во время обучения для разгрузки памяти)\n",
        "\n",
        "class NMROnTheFlyDataset(Dataset):\n",
        "    def __init__(self, num_samples: int):\n",
        "        self.num_samples = num_samples\n",
        "        self.W_MIN = 0.1\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        rng = torch.Generator()\n",
        "        rng.manual_seed(idx % (2**32))\n",
        "\n",
        "        # Генерация 1-4 компонент\n",
        "        probs = torch.tensor([0.25, 0.25, 0.25, 0.25])\n",
        "        n_comp = torch.multinomial(probs, 1, generator=rng).item() + 1\n",
        "\n",
        "        # Генерация T2 (Линейное пространство в диапазоне [0.1 с, 5.0 с])\n",
        "        u = torch.rand(n_comp, generator=rng)\n",
        "        T2 = u * (T2_MAX - T2_MIN) + T2_MIN\n",
        "        T2, _ = torch.sort(T2)\n",
        "\n",
        "        # Генерация весов w с минимальной долей 0.1\n",
        "        W_RANGE = 1.0 - self.W_MIN\n",
        "        w = torch.rand(n_comp, generator=rng) * W_RANGE + self.W_MIN\n",
        "        w = w / w.sum() # Нормализация, чтобы сумма = 1\n",
        "\n",
        "        # 1. ГЕНЕРАЦИЯ И НОРМАЛИЗАЦИЯ СИГНАЛА\n",
        "        signal = torch.zeros(N_POINTS)\n",
        "        for i in range(n_comp):\n",
        "            signal += w[i] * torch.exp(-T_ECHOES / T2[i])\n",
        "        signal += torch.normal(0.0, NOISE_STD, size=(N_POINTS,), generator=rng)\n",
        "        signal = torch.clamp(signal, min=1e-10)\n",
        "\n",
        "        # Нормализация сигнала\n",
        "        signal_norm_data = signal\n",
        "        mean = signal_norm_data.mean()\n",
        "        std = signal_norm_data.std() + 1e-8\n",
        "        signal_norm = (signal_norm_data - mean) / std\n",
        "\n",
        "        # 2. Создание истинного значения\n",
        "        y_param_true = torch.zeros(8)\n",
        "        y_param_true[:n_comp] = T2\n",
        "        y_param_true[4:4+n_comp] = w\n",
        "\n",
        "        return signal_norm.float().unsqueeze(0), y_param_true.float(), n_comp\n",
        "\n",
        "\n",
        "# 3. КЛАСС МОДЕЛИ\n",
        "class NMRParamCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv1d(1, 16, kernel_size=16, stride=1, padding='same'), nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "\n",
        "            nn.Conv1d(16, 32, kernel_size=16, stride=1, padding='same'), nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "\n",
        "            nn.Conv1d(32, 64, kernel_size=8, stride=1, padding='same'), nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=8, stride=1, padding='same'), nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "\n",
        "            nn.Conv1d(128, 256, kernel_size=8, stride=1, padding='same'), nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "        CONV_OUTPUT_SIZE = 256 * 64\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(CONV_OUTPUT_SIZE, 4096), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(4096, 1024), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 256), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(256, 8)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.fc_layers(x)\n",
        "\n",
        "        T2_out = x[:, :4]\n",
        "        w_out = x[:, 4:]\n",
        "\n",
        "        T2_out = torch.relu(T2_out)\n",
        "        w_out = F.softmax(w_out, dim=1)\n",
        "\n",
        "        return torch.cat([T2_out, w_out], dim=1)\n",
        "\n",
        "# 4. СПЕЦИАЛИЗИРОВАННАЯ ФУНКЦИЯ ПОТЕРИ\n",
        "\n",
        "def param_loss_fn(pred, target, n_comp, loss_func=nn.L1Loss(reduction='none')):\n",
        "    \"\"\"\n",
        "    Вычисляет L1 Loss только для существующих компонент T2 и w.\n",
        "    \"\"\"\n",
        "    batch_size = pred.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        num = n_comp[i].item()\n",
        "\n",
        "        if num > 0:\n",
        "            loss_t2 = loss_func(pred[i, :num], target[i, :num]).mean()\n",
        "            loss_w = loss_func(pred[i, 4:4+num], target[i, 4:4+num]).mean()\n",
        "\n",
        "            sample_loss = loss_t2 + loss_w\n",
        "            total_loss += sample_loss\n",
        "\n",
        "    return total_loss / batch_size\n",
        "\n",
        "\n",
        "# 5. ФУНКЦИЯ ДЛЯ ПРОВЕРКИ\n",
        "def test_model(model: nn.Module, dataset: Dataset, device: torch.device):\n",
        "    \"\"\"Проверяет модель на одном тестовом сэмпле с фиксированным seed=42,\n",
        "    отображая все 4 предсказанные компоненты.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    idx = 42\n",
        "    x, y_params_true, n_comp_true = dataset[idx]\n",
        "    x = x.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_params_tensor = model(x).squeeze().cpu()\n",
        "\n",
        "    # --- ИСТИННЫЕ ПАРАМЕТРЫ ---\n",
        "    T2_t_list = [f\"{y_params_true[j].item():.4f} с\" for j in range(4) if y_params_true[j+4] > 1e-8]\n",
        "    w_t_list = [f\"{y_params_true[j+4].item():.3f}\" for j in range(4) if y_params_true[j+4] > 1e-8]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"Истина ({n_comp_true} компонент): T2: {', '.join(T2_t_list)} | Доли: {', '.join(w_t_list)}\")\n",
        "\n",
        "    # --- ПРЕДСКАЗАННЫЕ ПАРАМЕТРЫ ---\n",
        "    pred_t2 = pred_params_tensor[:4].numpy()\n",
        "    pred_w = pred_params_tensor[4:].numpy()\n",
        "\n",
        "    pred_pairs = sorted([(pred_t2[i], pred_w[i]) for i in range(4)], key=lambda x: x[0])\n",
        "\n",
        "    T2_p_list = [f\"{t2:.4f} с\" for t2, w in pred_pairs]\n",
        "    w_p_list = [f\"{w:.3f}\" for t2, w in pred_pairs]\n",
        "    total_pred_w_sum = np.sum([w for t2, w in pred_pairs])\n",
        "\n",
        "    print(f\"Предсказание (4 компонент): T2: {', '.join(T2_p_list)} | Доли: {', '.join(w_p_list)}\")\n",
        "    print(f\"Сумма предсказанных долей: {total_pred_w_sum:.3f}\")\n",
        "\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "# 6. ЦИКЛ ОБУЧЕНИЯ\n",
        "\n",
        "def train_loop():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Устройство: {device}\")\n",
        "\n",
        "    train_ds = NMROnTheFlyDataset(2_000_000)\n",
        "    val_ds   = NMROnTheFlyDataset(100_000)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = NMRParamCNN().to(device)\n",
        "\n",
        "    # Загрузка предыдущей сохраненной модели\n",
        "    if os.path.exists(CHECKPOINT_PATH):\n",
        "        model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\n",
        "        print(\"Загружена сохранённая CNN-модель.\")\n",
        "    else:\n",
        "        model.apply(init_weights)\n",
        "        print(\"Чекпоинт не найден. Обучение начинается с нуля.\")\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=4)\n",
        "\n",
        "    best_val = float('inf')\n",
        "    EPOCHS = 200\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for x, y_param_true, n_comp in tqdm(train_loader, desc=f\"Epoch {epoch:3d}\"):\n",
        "            x, y_param_true = x.to(device), y_param_true.to(device)\n",
        "\n",
        "            pred = model(x)\n",
        "            loss = param_loss_fn(pred, y_param_true, n_comp)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for x, y_param_true, n_comp in val_loader:\n",
        "                x, y_param_true = x.to(device), y_param_true.to(device)\n",
        "                val_loss += param_loss_fn(model(x), y_param_true, n_comp).item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch:3d} | Train {train_loss:.5f} | Val {val_loss:.5f}\")\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
        "            print(f\"  BEST! val = {val_loss:.5f} → сохранено\")\n",
        "\n",
        "        if epoch % 5 == 0 or val_loss == best_val:\n",
        "            test_model(model, val_ds, device)\n",
        "\n",
        "    print(\"Готово. Лучший val_loss:\", best_val)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_loop()"
      ]
    }
  ]
}